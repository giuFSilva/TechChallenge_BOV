{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Capturando os dados\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "73RIZ2udq4D9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkTQEkQTU3X2"
      },
      "outputs": [],
      "source": [
        "#importando as bibliotecas\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lendo o arquivo que baixei da investing\n",
        "df_base_original = pd.read_csv('/content/dados_ibovespa1.csv')"
      ],
      "metadata": {
        "id": "krGnlsevU9Nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#conferindo que os dados subiram no DF\n",
        "df_base_original.head()"
      ],
      "metadata": {
        "id": "tXdf6fEAVHQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#analisando os tipos de dados\n",
        "df_base_original.info()"
      ],
      "metadata": {
        "id": "Z0_yyYvoVQUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.   Preparação dos dados\n",
        "\n"
      ],
      "metadata": {
        "id": "-X-bnlXUrB0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convertendo a data para datetime\n",
        "df_base_original['Data'] = pd.to_datetime(df_base_original['Data'], format='%d.%m.%Y')\n",
        "\n",
        "#Limpando e convertendo 'Vol.' para float, removendo a letra 'M' e K, convertendo para milhões e milhares\n",
        "df_base_original['Vol.'] = df_base_original['Vol.'].replace({'M': 'e6', 'K': 'e3'}, regex=True).replace(',', '.', regex=True).astype(float)\n",
        "\n",
        "# Convertendo o 'Var%' para float, removendo o símbolo '%' e dividindo por 100\n",
        "df_base_original['Var%'] = df_base_original['Var%'].str.replace('%', '').str.replace(',', '.').astype(float) / 100"
      ],
      "metadata": {
        "id": "SeWGZO85VRiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removendo espaços e caracteres especiais dos nomes das colunas\n",
        "df_base_original.columns = df_base_original.columns.str.strip().str.lower().str.replace('%', '').str.replace('.', '').str.replace(' ', '_')"
      ],
      "metadata": {
        "id": "SIkMryqylTWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instalando uma biblioteca para tratativa da acentuação do nome das colunas, espaços existentes e deixando tudo em letra minuscula\n",
        "!pip install unidecode"
      ],
      "metadata": {
        "collapsed": true,
        "id": "F-A4D0JSmi9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unidecode\n",
        "df_base_original.columns = [unidecode.unidecode(col).strip().lower() for col in df_base_original.columns]"
      ],
      "metadata": {
        "id": "mtWuNdF8m0gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exportando o DataFrame para um arquivo Excel para analisar o estado completo do arquivo\n",
        "df_base_original.to_excel('df_base_tratada.xlsx', index=False)"
      ],
      "metadata": {
        "id": "GKAs6r9WpjsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preencher valores ausentes na coluna 'vol' com a média, descobri que há uma linha com o dado vazio\n",
        "df_base_original['vol'].fillna(df_base_original['vol'].mean(), inplace=True)"
      ],
      "metadata": {
        "id": "dm4lo8L6qe2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#revalidando através de função que deu certo e não há dados em branco\n",
        "df_base_original.isnull().sum()"
      ],
      "metadata": {
        "id": "Y08CEJ9IrblF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#verificação das mudanças\n",
        "print(df_base_original.columns)\n"
      ],
      "metadata": {
        "id": "f19DFmZhfj4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Explorando os dados"
      ],
      "metadata": {
        "id": "J2G98TVvr0_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenação por data\n",
        "df_base_original = df_base_original.sort_values('data')\n",
        "\n",
        "# Plote da série temporal do fechamento diário\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.plot(df_base_original['data'], df_base_original['ultimo'], label='Fechamento')\n",
        "plt.title('Série Temporal do Fechamento Diário do IBOVESPA')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('Fechamento (R$)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "w-a9XG6em5Me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurações do estilo para o grafico com indicadores de queda\n",
        "plt.style.use('seaborn-darkgrid')\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Linha do fechamento\n",
        "plt.plot(df_base_original['data'], df_base_original['ultimo'], color='lightblue', label='Fechamento')\n",
        "\n",
        "# Calculo das quedas significativas, maior que 5% - circuit break\n",
        "df_base_original['var_percentual'] = df_base_original['ultimo'].pct_change() * 100\n",
        "df_base_original['queda_significativa'] = df_base_original['var_percentual'] < -5\n",
        "\n",
        "# Adicionando áreas sombreadas para quedas significativas\n",
        "plt.fill_between(df_base_original['data'], df_base_original['ultimo'],\n",
        "                 where=df_base_original['queda_significativa'], color='red', alpha=0.3,\n",
        "                 label='Quedas Significativas (>5%)')\n",
        "\n",
        "# Média móvel para suavizar os dados\n",
        "df_base_original['media_movel'] = df_base_original['ultimo'].rolling(window=30).mean()\n",
        "plt.plot(df_base_original['data'], df_base_original['media_movel'], color='blue', linestyle='--',\n",
        "         label='Média Móvel (30 dias)')\n",
        "\n",
        "# Personalização do gráfico\n",
        "plt.title('Histórico de Fechamento do IBOVESPA (2004-2024)', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Data', fontsize=12)\n",
        "plt.ylabel('Fechamento', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-4ZiFzQLr26s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Decomposição da série temporal com base nas datas\n",
        "result = sm.tsa.seasonal_decompose(df_base_original['ultimo'], model='additive', period=252)\n",
        "plt.rcParams.update({'figure.figsize': (10, 10)})\n",
        "result.plot()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lFvDbMeFpPBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Criação do modelo"
      ],
      "metadata": {
        "id": "kGbpg5I_f6lA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install prophet"
      ],
      "metadata": {
        "id": "JLI5UgGLzLjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from prophet import Prophet\n",
        "\n",
        "#Dados exigidos para analise\n",
        "df_prophet = df_base_original[['data', 'ultimo']].rename(columns={'data': 'ds', 'ultimo': 'y'})\n",
        "\n",
        "# Filtrar dados até o final de 2018-02-22 que é o valor de 70% da minha base\n",
        "df_filtered = df_prophet[df_prophet['ds'] < '2018-02-24']\n",
        "train_data = df_filtered\n",
        "\n",
        "# atribuindo os dados para teste a partir de 2018-02-22, os 30% restante\n",
        "test_data = df_prophet[df_prophet['ds'] >= '2018-02-24']\n",
        "\n",
        "# Exibindo a divisão\n",
        "print(f\"Tamanho do treino: {len(train_data)}\")\n",
        "print(f\"Tamanho do teste: {len(test_data)}\")\n"
      ],
      "metadata": {
        "id": "xBRh-NjSf0jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gerando o excel para conferir os dados\n",
        "test_data.to_excel('test_data.xlsx', index=False)\n",
        "train_data.to_excel('train_data.xlsx', index=False)"
      ],
      "metadata": {
        "id": "NNy4JdpOUdQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gerando uma visualização grafics dos dados de treino e teste\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plotar dados de treino\n",
        "plt.plot(train_data['ds'], train_data['y'], label='Dados de Treino', color='blue')\n",
        "\n",
        "# Plotar dados de teste\n",
        "plt.plot(test_data['ds'], test_data['y'], label='Dados de Teste', color='orange')\n",
        "\n",
        "plt.title('Comparação entre Dados de Treino e Dados de Teste')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('Valor de Fechamento')\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qFpYTKCmQBpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prophet import Prophet\n",
        "from prophet.make_holidays import make_holidays_df\n",
        "\n",
        "# Criando o modelo Prophet\n",
        "model = Prophet(\n",
        "    yearly_seasonality=True,\n",
        "    weekly_seasonality=True,\n",
        "    daily_seasonality=True,\n",
        "    changepoint_prior_scale=0.3,\n",
        "    seasonality_mode='additive',\n",
        "    interval_width=0.95\n",
        ")\n",
        "\n",
        "# Extrair os anos que temos na base para criação do mapeamento de feriados usando a função make_holidays_df\n",
        "years = df_prophet['ds'].dt.year.unique()\n",
        "\n",
        "# Feriados estaduais e municipais\n",
        "sp_holidays = make_holidays_df(\n",
        "    year_list=years,\n",
        "    country='BR', province='SP',\n",
        ")\n",
        "\n",
        "# Feriados nacionais\n",
        "br_holidays = make_holidays_df(\n",
        "    year_list=years,\n",
        "    country='BR',\n",
        ")\n",
        "\n",
        "# Mensalão\n",
        "mensalao = pd.DataFrame({\n",
        "    'holiday': 'Escândalo do Mensalão',\n",
        "    'ds': pd.to_datetime(['2005-01-01', '2005-06-01']),  # Datas representativas do escândalo\n",
        "    'lower_window': 0,\n",
        "    'upper_window': 0,\n",
        "})\n",
        "\n",
        "# Pré-sal\n",
        "pre_sal = pd.DataFrame({\n",
        "    'holiday': 'Descoberta Pré-sal',\n",
        "    'ds': pd.to_datetime(['2006-01-01']),\n",
        "    'lower_window': 0,\n",
        "    'upper_window': 0,\n",
        "})\n",
        "\n",
        "# Crise Financeira 2008\n",
        "crise_2008 = pd.DataFrame({\n",
        "    'holiday': 'Crise Financeira 2008',\n",
        "    'ds': pd.to_datetime(['2008-09-15']),\n",
        "    'lower_window': -5,\n",
        "    'upper_window': 0,\n",
        "})\n",
        "\n",
        "# Crise da Dívida da Europa\n",
        "crise_divida_europa = pd.DataFrame({\n",
        "    'holiday': 'Crise da Dívida da Europa',\n",
        "    'ds': pd.to_datetime(['2012-01-01', '2012-06-01', '2012-11-01']),  # Datas representativas da crise\n",
        "    'lower_window': 0,\n",
        "    'upper_window': 0,\n",
        "})\n",
        "\n",
        "# Impeachment 2014\n",
        "impeachment = pd.DataFrame({\n",
        "    'holiday': 'Impeachment 2014',\n",
        "    'ds': pd.to_datetime(['2014-03-01']),\n",
        "    'lower_window': -5,\n",
        "    'upper_window': 5,\n",
        "})\n",
        "\n",
        "# Eleições a cada 4 anos, a partir de 2002\n",
        "anos_eleicoes = np.arange(2002, 2026, 4)\n",
        "dia_mes = ['10-04'] * len(anos_eleicoes)\n",
        "datas_eleicoes = [f'{ano}-{dia}' for ano, dia in zip(anos_eleicoes, dia_mes)]\n",
        "\n",
        "eleicoes = pd.DataFrame({\n",
        "    'holiday': 'Eleição Presidencial',\n",
        "    'ds': pd.to_datetime(datas_eleicoes),\n",
        "    'lower_window': -3,\n",
        "    'upper_window': 4,\n",
        "})\n",
        "\n",
        "# Juntar as bases\n",
        "holidays_df = pd.concat([sp_holidays, br_holidays, mensalao, pre_sal, crise_2008, impeachment, eleicoes, crise_divida_europa])\n",
        "holidays_df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Usar atribuição direta para evitar warnings\n",
        "holidays_df['upper_window'] = holidays_df['upper_window'].fillna(4)\n",
        "holidays_df['lower_window'] = holidays_df['lower_window'].fillna(-3)\n",
        "\n",
        "# Adicionar sazonalidades personalizadas\n",
        "model.add_seasonality(name='yearly', period=365.25, fourier_order=10)\n",
        "model.add_seasonality(name='weekly', period=7, fourier_order=10)\n",
        "\n",
        "# Treinar o modelo\n",
        "model.fit(df_prophet)\n"
      ],
      "metadata": {
        "id": "fdW6MFh0sQ15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# colocando a previsão do mesmo tamanho que a base de testes\n",
        "n_periods = len(test_data)\n",
        "future = model.make_future_dataframe(periods=n_periods)\n",
        "\n",
        "# Criar DataFrame futuro\n",
        "forecast = model.predict(future)\n",
        "\n",
        "# Filtrar as previsões até 2024\n",
        "forecast = forecast[forecast['ds'] <= '2024-03-31']"
      ],
      "metadata": {
        "id": "qbIbCvU8jfn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Previsões para os dados de teste\n",
        "forecast_test = forecast[forecast['ds'].isin(test_data['ds'])]\n",
        "\n",
        "# Pegando as previsões para as datas que estão tanto no forecast quanto no test_data\n",
        "common_dates = forecast_test['ds'].isin(test_data['ds'])\n",
        "y_true = test_data[test_data['ds'].isin(forecast_test['ds'])]['y'].values\n",
        "y_pred = forecast_test[common_dates]['yhat'].values\n",
        "\n",
        "# Verificando os tamanhos\n",
        "print(f\"Tamanho de y_true: {len(y_true)}\")\n",
        "print(f\"Tamanho de y_pred: {len(y_pred)}\")\n",
        "\n",
        "# Calcular métricas se os tamanhos forem iguais\n",
        "if len(y_true) == len(y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    print(f'MAE: {mae}')\n",
        "    print(f'RMSE: {rmse}')\n",
        "    print(f'R²: {r2}')\n",
        "else:\n",
        "    print(\"Erro: os tamanhos de y_true e y_pred ainda não correspondem.\")\n"
      ],
      "metadata": {
        "id": "tKgicSyQjmUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Duplicatas em test_data:\")\n",
        "print(test_data[test_data.duplicated(subset='ds')])\n",
        "\n",
        "print(\"Valores nulos em forecast:\")\n",
        "print(forecast[forecast['yhat'].isnull()])\n"
      ],
      "metadata": {
        "id": "gKgFZB9DW68z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando últimas 10 previsões\n",
        "print(forecast[['ds', 'yhat']].tail(10))\n"
      ],
      "metadata": {
        "id": "Zl94kyhMXP0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Grafico das comparações\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(test_data['ds'], test_data['y'], label='Real', color='blue')\n",
        "plt.plot(forecast['ds'], forecast['yhat'], label='Previsto', color='red', linestyle='--')\n",
        "plt.axvline(x=test_data['ds'].min(), color='gray', linestyle='--', label='Início do Teste')\n",
        "plt.title('Comparação de Previsões')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('Valores')\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "W16DQKNSXdde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#grafico das comparações com foco nos dados previstos\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Criar um DataFrame com os valores reais e as previsões\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Data': forecast_test['ds'],\n",
        "    'Real': y_true,\n",
        "    'Previsão': y_pred\n",
        "})\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(comparison_df['Data'], comparison_df['Real'], label='Valor Real', color='blue')\n",
        "plt.plot(comparison_df['Data'], comparison_df['Previsão'], label='Valor Previsto', color='red', linestyle='--')\n",
        "plt.title('Comparação entre o Valor Real e o Valor Previsto do Ibovespa')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('Valor de Fechamento')\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sgCxltymz4wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validação cruzada\n",
        "from prophet.diagnostics import cross_validation, performance_metrics\n",
        "\n",
        "initial = '1825 days'\n",
        "horizon = '150 days'\n",
        "period = '150 days'\n",
        "\n",
        "df_cv = cross_validation(model, initial=initial, period=period, horizon=horizon)\n",
        "\n",
        "# Calcular as métricas de performance\n",
        "df_p = performance_metrics(df_cv)\n",
        "\n",
        "# Visualizar as primeiras linhas das métricas\n",
        "print(df_p.head())\n",
        "\n",
        "# Visualizar as métricas de desempenho\n",
        "print(\"Métricas de Desempenho:\")\n",
        "print(f\"Mean Absolute Error (MAE): {df_p['mae'].mean()}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {df_p['rmse'].mean()}\")\n",
        "print(f\"Mean Absolute Percentage Error (MAPE): {df_p['mape'].mean()}\")\n"
      ],
      "metadata": {
        "id": "Ndbk8h6_mSEH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}